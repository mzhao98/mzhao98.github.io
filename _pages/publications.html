---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

{% if site.author.googlescholar %}
  <div class="wordwrap">You can also find my articles on <a href="{{site.author.googlescholar}}">my Google Scholar profile</a>.</div>
{% endif %}

{% include base_path %}

<!-- New style rendering if publication categories are defined -->
<style>
    .container {
        display: flex;
        align-items: center;
        width: 100%;
        /*max-width: 800px; !* Adjust as needed *!*/
        margin: 0 auto;
    }
    .text {
        width: 75%;
        /*padding-right: 20px;*/
    }
    .image {
        width: 25%;
        padding-right: 20px;
    }
    .image img {
        width: 100%;
        height: auto;
        display: block;
    }
</style>


<br><br><h1>Conference Papers</h1><hr />


<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">


  <h2 class="archive__item-title" itemprop="headline">
        <a href="https://arxiv.org/abs/2410.08852" rel="permalink">Conformalized Interactive Imitation Learning: Handling Expert Shift and Intermittent Feedback
    </a>
    </h2>
    <strong>Michelle Zhao</strong>, Reid Simmons, Henny Admoni, Aaditya Ramdas*, Andrea Bajcsy*
    <br>
    <em>ICLR</em>, 2025
    <br>
    <a href="https://cmu-intentlab.github.io/conformalized-interactive-il/">project site</a> /
    <a href="https://arxiv.org/pdf/2410.08852">paper</a> /
    <a href="http://localhost:4000/publications/data/zhao_conformalized_iclr_2025.bib">bibtex</a>
<!--                <a href="https://www.youtube.com/watch?v=rkydo1yUGZY">video</a>-->

  <!-- make image 25% of the width, with the text taking up the rest -->
    <div class="container">
        <div class="image" style="width: 150px; height: 150px ">
            <img src="http://localhost:4000/images/cdagger_real.png" alt="Sample Image">
        </div>
<!--        <div class="text">-->
        <!-- make font size smaller-->
        <div class="text" style="font-size: 0.8em;">
            <p>
                Uncertainty quantification offers a way for the learner (i.e. robot)
                to contend with distribution shifts encountered during deployment by actively seeking additional feedback
                from an expert (i.e. human) online. From the conformal prediction side, we introduce a novel uncertainty
                quantification algorithm called intermittent quantile tracking (IQT) that leverages a probabilistic
                model of intermittent labels, maintains asymptotic coverage guarantees, and empirically achieves
                desired coverage levels. From the interactive IL side, we develop ConformalDAgger, a new approach
                wherein the robot uses prediction intervals calibrated by IQT as a reliable measure of deployment-time
                uncertainty to actively query for more expert feedback.
            </p>
        </div>

    </div>

  </article>
</div>


<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">

      <h2 class="archive__item-title" itemprop="headline">
        <a href="https://arxiv.org/pdf/2406.07767" rel="permalink">Conformalized Teleoperation: Confidently Mapping Human Inputs to High-Dimensional Robot Action
        </a>
        </h2>
        <strong>Michelle Zhao</strong>, Reid Simmons, Henny Admoni, Andrea Bajcsy
        <br>
        <em>RSS</em>, 2024
        <br>
        <a href="https://cmu-intentlab.github.io/conformalized-teleoperation/">project site</a> /
        <a href="https://arxiv.org/pdf/2406.07767">paper</a> /
        <a href="http://localhost:4000/publications/data/zhao_conformalized_rss_2024.bib">bibtex</a> /
        <a href="https://www.youtube.com/watch?v=rkydo1yUGZY">video</a>

      <div class="container">
        <div class="image" style="width: 150px; height: 150px ">
            <img src="http://localhost:4000/images/con_teleop.png" alt="Sample Image">
        </div>
        <div class="text" style="font-size: 0.8em;">
            <p>
            Assistive robotic arms often have more degrees-of-freedom than a human teleoperator can control with
            a low-dimensional input, like a joystick. To overcome this challenge, existing approaches use
            data-driven methods to learn a mapping from low-dimensional human inputs to high-dimensional
            robot actions. However, determining if such a black-box mapping can confidently infer a user's
            intended high-dimensional action from low-dimensional inputs remains an open problem. Our key idea
            is to adapt the assistive map at training time to additionally estimate high-dimensional action
            quantiles, and then calibrate these quantiles via rigorous uncertainty quantification methods.
            </p>
        </div>

    </div>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">

      <h2 class="archive__item-title" itemprop="headline">
        <a href="https://arxiv.org/pdf/2311.11955" rel="permalink">Multi-Agent Strategy Explanations for Human-Robot Collaboration
        </a>
        </h2>
        Ravi Pandya*, <strong>Michelle Zhao*</strong>, Changliu Liu, Reid Simmons, Henny Admoni
        <br>
        <em>ICRA</em>, 2024
        <br>
            <a href="https://arxiv.org/pdf/2311.11955">paper</a> /
        <a href="http://localhost:4000/publications/data/pandya_multi_icra_2024.bib">bibtex</a>

      <div class="container">
        <div class="image" style="width: 120px">
            <img src="http://localhost:4000/images/strats2.png" alt="Sample Image">
        </div>
        <div class="text" style="font-size: 0.8em;">
            <p>
            Part of such coordination involves ensuring that people have a good understanding of how a robot will act in the environment. This can
            be achieved through explanations of the robot’s policy. In this work, we investigate how
            to generate multi-agent strategy explanations for human-robot collaboration. We formulate the problem using a generic multi-agent planner, show how
            to generate visual explanations through strategy-conditioned landmark states and generate textual explanations by giving the landmarks to an LLM. Through a
            user study, we find that when presented with explanations from our proposed framework, users are able to better explore the full space of strategies and
            collaborate more efficiently with new robot partners.
            </p>
        </div>

    </div>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
  <h2 class="archive__item-title" itemprop="headline">
    <a href="https://openreview.net/pdf?id=7CtUcT_OHmC" rel="permalink">Learning Human Contribution Preferences in Collaborative Human-Robot Tasks
    </a>
    </h2>
    <strong>Michelle Zhao</strong>, Reid Simmons, Henny Admoni
    <br>
    <em>CORL</em>, 2023
    <br>
    <a href="https://openreview.net/pdf?id=7CtUcT_OHmC">paper</a> /
    <a href="http://localhost:4000/publications/data/zhao_topics_adaptation_2022.bib">bibtex</a>

  <div class="container">
    <div class="image" style="width: 150px">
        <img src="http://localhost:4000/images/baisl_robots.png" alt="Sample Image">
    </div>
    <div class="text" style="font-size: 0.8em;">
        <p> Effective teams align their actions to optimize task performance while satisfying each team
            member’s constraints to the greatest extent possible. We propose a framework for representing human and robot
            contribution constraints in collaborative human-robot tasks. Additionally, we present an approach for learning a
            human partner’s contribution constraint online during a collaborative interaction. We evaluate our approach using a
            variety of simulated human partners in a collaborative decluttering task. Our results demonstrate that our method
            improves team performance over baselines with some, but not all, simulated human partners.
        </p>
    </div>

    </div>

  </article>
</div>


<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
  <h2 class="archive__item-title" itemprop="headline">
    <a href="https://ieeexplore.ieee.org/iel7/9981026/9981028/09982277.pdf" rel="permalink">Coordination With Humans Via Strategy Matching
    </a>
    </h2>
    <strong>Michelle Zhao</strong>, Reid Simmons, Henny Admoni
    <br>
    <em>IROS</em>, 2022
    <br>
    <a href="http://localhost:4000/publications/data/zhao_coordination_iros2022.pdf">paper</a> /
    <a href="http://localhost:4000/publications/data/zhao_topics_adaptation_2022.bib">bibtex</a> /
    <a href="https://www.youtube.com/watch?v=j40Mpg8wiuU">video</a>

  <div class="container">
    <div class="image" style="width: 150px">
        <img src="http://localhost:4000/images/zhao_coordination_cover.png" alt="Sample Image">
    </div>
    <div class="text" style="font-size: 0.8em;">
        <p>This work autonomously recognizes available task-completion strategies by observing human-human teams performing a collaborative task. By
      transforming team actions into low dimensional representations using hidden Markov models, we can
      identify strategies without prior knowledge. Robot policies are learned on each of the identified
      strategies to construct a Mixture-of-Experts model that adapts to the task strategies of unseen human
      partners.
        </p>
    </div>

    </div>

  </article>
</div>


<br><br><h1>Journal Articles</h1><hr />

<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">

  <h2 class="archive__item-title" itemprop="headline">
    <a href="https://onlinelibrary.wiley.com/doi/10.1111/tops.12633" rel="permalink">The Role of Adaptation in Collective Human–AI Teaming
    </a>
    </h2>
    <strong>Michelle Zhao</strong>, Reid Simmons, Henny Admoni
    <br>
    <em>Topics in Cognitive Science</em>, 2022
    <br>
    <a href="data/zhao_adaptation_topics_2022.pdf">paper</a> /
    <a href="data/zhao_topics_adaptation_2022.bib">bibtex</a>

  <div class="container">
    <div class="image" style="width: 150px">
        <img src="http://localhost:4000/images/zhao_topics_cover_game.png" alt="Sample Image">
    </div>
    <div class="text" style="font-size: 0.8em;">
        <p>
       This paper presents a framework for defining artificial intelligence (AI) that adapts to individuals within a group,
      and discusses the technical challenges for collaborative AI systems that must work with different human partners.
      Collaborative AI is not one-size-fits-all, and thus AI systems must tune their output based on each human partner's
      needs and abilities.
        </p>
    </div>

    </div>
  </article>
</div>



<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
  <h2 class="archive__item-title" itemprop="headline">
    <a href="https://www.sciencedirect.com/science/article/pii/S0747563222003442" rel="permalink">Teaching Agents to Understand Teamwork: Evaluating and Predicting Collective
        Intelligence as a Latent Variable via Hidden Markov Models
    </a>
    </h2>
    <strong>Michelle Zhao*</strong>, Fade Eadeh*, Thuy-Ngoc Nguyen, Pranay Gupta, Henny Admoni, Cleotide Gonzalez, Anita Williams Woolley
    <br>
    <em>Computers in Human Behavior</em>, 2022
    <br>
    <a href="http://localhost:4000/publications/data/zhao_teaching_chb_2022.pdf">paper</a> /
    <a href="http://localhost:4000/publications/data/zhao_topics_adaptation_2022.bib">bibtex</a>
  <div class="container">
    <div class="image" style="width: 150px">
        <img src="http://localhost:4000/images/minimap.png" alt="Sample Image">
    </div>
    <div class="text" style="font-size: 0.8em;">
        <p>
       We show by learning the set of hidden states representing a team’s observed collaborative process
      behaviors over time, we both learn information about the team’s collective intelligence (CI), predict how CI will evolve in
      the future, and suggest when an agent might intervene to improve team performance.
        </p>
    </div>

    </div>
  </article>
</div>




<br><br><h1>Workshop Papers</h1><hr />


<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
  <h2 class="archive__item-title" itemprop="headline">
    <a href="http://localhost:4000/publications/data/MZ_research_statement_oct24.pdf" rel="permalink">Towards Proactive Robot Learners that Ask for Help
        Intelligence as a Latent Variable via Hidden Markov Models
    </a>
    </h2>
    <strong>Research Statement</strong>
    <br>
  <div class="container">
    <div class="image" style="width: 150px">
        <img src="http://localhost:4000/images/research_overview.png" alt="Sample Image">
    </div>
    <div class="text" style="font-size: 0.8em;">
        <p>
       While today’s robot learning algorithms increasingly enable people to teach robots via diverse forms of feedback, they
        place the burden of responsibility on the human to perfectly understand what the robot doesn’t know and provide the
        “right” data. My research contends that robots should be proactive participants— they should bear some of the burden
        of knowing when they don’t know and should ask for targeted help. I tackle this problem by extending foundational
        uncertainty quantification techniques to the HRI setting, enabling robots to rigorously “know when they don’t know”
        even when relying on black-box policies and to ask for strategic help.
        </p>
    </div>

    </div>
  </article>
</div>



<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
  <h2 class="archive__item-title" itemprop="headline">
    <a href="https://rlconform-workshop.github.io/pdfs/4_2023_RL_Conform_Camera_Ready.pdf" rel="permalink">Machine Teaching of Collaborative Policies for Human Inverse Reinforcement Learning
        Intelligence as a Latent Variable via Hidden Markov Models
    </a>
    </h2>
    Nyomi Morris, <strong>Michelle Zhao</strong>, Reid Simmons, Henny Admoni
    <br>
    <em>RL-CONFORM Workshop: RL Meets HRI, Control, and Formal Methods (IROS)</em>, 2023
    <br>
    <a href="https://rlconform-workshop.github.io/pdfs/4_2023_RL_Conform_Camera_Ready.pdf">workshop paper</a>
  <div class="container">
    <div class="image" style="width: 150px">
        <img src="http://localhost:4000/images/teaching_diagram.png" alt="Sample Image">
    </div>
    <div class="text" style="font-size: 0.8em;">
        <p>
       We consider the problem of teaching a human partner a joint reward function, which captures how both
      human and robot should contribute to the task. This reward, which is known only to the robot, is
      joint over human and robot actions, and encompasses constraints over how the human and robot should
      contribute to a task. By adapting existing machine teaching frameworks for our collaborative domain,
      we seek to provide a minimal number of demonstrations such that a human can learn the rewards.
        </p>
      <p style="color: red">
<!--                  make red and bold-->
        <strong>Best Poster Presentation Award</strong>

    </p>
    </div>

    </div>
  </article>
</div>





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
  <h2 class="archive__item-title" itemprop="headline">
    <a href="https://ai4athome.github.io/res/papers/chen_learning_human_preferences.pdf" rel="permalink">Learning Human Preferences for Personalized Assistance in Household Tasks
    </a>
    </h2>
    Daphne Chen, <strong>Michelle Zhao</strong>, Reid Simmons
    <br>
    <em>AAAI Workshop on User-Centric Artificial Intelligence for Assistance in At-Home Tasks</em>, 2023
    <br>
    <a href="https://ai4athome.github.io/res/papers/chen_learning_human_preferences.pdf">workshop paper</a>
  <div class="container">
    <div class="image" style="width: 150px">
        <img src="http://localhost:4000/images/ai2thor.png" alt="Sample Image">
    </div>
    <div class="text" style="font-size: 0.8em;">
        <p>
       We propose a method for generating a customizable quantity of synthetic data that reflects the variability
      in task execution styles seen in the real-world task, and enables us to train a baseline sequential
      model that predicts the next action a participant will take within a cooking activity.
        </p>
    </div>

    </div>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
  <h2 class="archive__item-title" itemprop="headline">
    <a href=http://packages.personalrobotics.ri.cmu.edu/assets/pubs/zhao_adapting_hri_leap_workshop_2021.pdf" rel="permalink">Adapting Language Complexity for Ai-Based Assistance
    </a>
    </h2>
    <strong>Michelle Zhao</strong>, Reid Simmons, Henny Admoni
    <br>
    <em>ACM/IEEE International Conference on Human Robot Interaction, Lifelong Learning and Personalization in Long-Term Human-Robot Interaction (LEAP-HRI)</em>, 2021
    <br>
    <a href="http://packages.personalrobotics.ri.cmu.edu/assets/pubs/zhao_adapting_hri_leap_workshop_2021.pdf">workshop paper</a>
  <div class="container">
    <div class="image" style="width: 150px">
        <img src="http://localhost:4000/images/loops.png" alt="Sample Image">
    </div>
    <div class="text" style="font-size: 0.8em;">
        <p>
      We present a closed-loop interaction framework that adapts the level of information complexity based
          on the human partner’s observable cognitive understanding. This work investigates how
          knowledge and preparation impact the suitability of di erent complexity levels, motivating dynamic interaction.
    </p>
    </div>

    </div>
  </article>
</div>



